Container nvidia build =  13409399
XLA activated
2020-12-16 17:49:39.903772: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1216 17:49:41.575091 140149878220608 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f75974eee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1216 17:49:42.307803 140149878220608 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f75974eee80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f75974f2bf8>) includes params argument, but params are not passed to Estimator.
W1216 17:49:42.308592 140149878220608 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f75974f2bf8>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1216 17:49:42.309068 140149878220608 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 48
I1216 17:49:42.309146 140149878220608 run_pretraining.py:624]   Batch size = 48
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1216 17:49:42.425931 140149878220608 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1216 17:49:42.553939 140149878220608 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1216 17:49:42.554130 140149878220608 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (48, 128)
I1216 17:49:42.554245 140149878220608 run_pretraining.py:259]   name = input_ids, shape = (48, 128)
INFO:tensorflow:  name = input_mask, shape = (48, 128)
I1216 17:49:42.554490 140149878220608 run_pretraining.py:259]   name = input_mask, shape = (48, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (48, 20)
I1216 17:49:42.554575 140149878220608 run_pretraining.py:259]   name = masked_lm_ids, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (48, 20)
I1216 17:49:42.554655 140149878220608 run_pretraining.py:259]   name = masked_lm_positions, shape = (48, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (48, 20)
I1216 17:49:42.554732 140149878220608 run_pretraining.py:259]   name = masked_lm_weights, shape = (48, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (48, 1)
I1216 17:49:42.554807 140149878220608 run_pretraining.py:259]   name = next_sentence_labels, shape = (48, 1)
INFO:tensorflow:  name = segment_ids, shape = (48, 128)
I1216 17:49:42.554880 140149878220608 run_pretraining.py:259]   name = segment_ids, shape = (48, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1216 17:49:42.555102 140149878220608 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1216 17:49:42.556408 140149878220608 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1216 17:49:44.425030 140149878220608 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1216 17:49:48.127924 140149878220608 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1216 17:49:57.472462 140149878220608 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1216 17:49:57.474064 140149878220608 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1216 17:50:02.251405 140149878220608 monitored_session.py:240] Graph was finalized.
2020-12-16 17:50:02.261889: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-16 17:50:02.264183: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x103c2600 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-16 17:50:02.264243: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-16 17:50:02.267375: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-16 17:50:02.745552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:50:02.747016: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x104a4ba0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-16 17:50:02.747045: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-16 17:50:02.747328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:50:02.749567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0b.0
2020-12-16 17:50:02.749628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-16 17:50:02.753351: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-16 17:50:02.754959: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-16 17:50:02.755337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-16 17:50:02.758599: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-16 17:50:02.759321: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-16 17:50:02.759539: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-16 17:50:02.759654: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:50:02.760987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:50:02.762248: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-16 17:50:02.762303: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-16 17:50:03.353052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-16 17:50:03.353169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-16 17:50:03.353195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-16 17:50:03.353915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:50:03.357817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:50:03.362780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14799 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0)
2020-12-16 17:50:10.166067: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
INFO:tensorflow:Running local_init_op.
I1216 17:50:15.767625 140149878220608 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1216 17:50:16.381706 140149878220608 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1/model.ckpt.
I1216 17:50:28.567097 140149878220608 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1/model.ckpt.
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1216 17:50:36.770995 140149878220608 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2020-12-16 17:50:58.712393: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-16 17:50:59.447385: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-16 17:51:20.130166: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.19462, step = 0
I1216 17:51:26.953617 140149878220608 basic_session_run_hooks.py:262] loss = 11.19462, step = 0
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 17:52:10.223257 140149878220608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 17:52:10.535488 140149878220608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 17:52:10.849020 140149878220608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 17:52:11.159654 140149878220608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 17:52:11.474863 140149878220608 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
INFO:tensorflow:loss = 11.107853, step = 7 (3351.331 sec)
I1216 18:47:18.284824 140149878220608 basic_session_run_hooks.py:260] loss = 11.107853, step = 7 (3351.331 sec)
INFO:tensorflow:loss = 11.080696, step = 14 (3239.010 sec)
I1216 19:41:17.294354 140149878220608 basic_session_run_hooks.py:260] loss = 11.080696, step = 14 (3239.010 sec)
INFO:tensorflow:loss = 11.10723, step = 21 (3239.692 sec)
I1216 20:35:16.986177 140149878220608 basic_session_run_hooks.py:260] loss = 11.10723, step = 21 (3239.692 sec)
INFO:tensorflow:loss = 11.104807, step = 28 (3238.309 sec)
I1216 21:29:15.294912 140149878220608 basic_session_run_hooks.py:260] loss = 11.104807, step = 28 (3238.309 sec)
INFO:tensorflow:loss = 11.036578, step = 35 (3240.411 sec)
I1216 22:23:15.705809 140149878220608 basic_session_run_hooks.py:260] loss = 11.036578, step = 35 (3240.411 sec)
decayed_learning_rate_at_crossover_point = 7.500000e-04, adjusted_init_lr = 7.500000e-04
Initializing LAMB Optimizer
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 18:00:14.663928 - Iteration: 2  throughput_train : 117.149 seq/s mlm_loss : 10.4252  nsp_loss : 0.7193  total_loss : 11.1445  avg_loss_step : 11.1222  learning_rate : 0.0
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 18:07:49.876717 - Iteration: 3  throughput_train : 148.544 seq/s mlm_loss : 10.4171  nsp_loss : 0.6738  total_loss : 11.0909  avg_loss_step : 11.1213  learning_rate : 3.75e-07
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 18:15:26.284849 - Iteration: 4  throughput_train : 148.155 seq/s mlm_loss : 10.4625  nsp_loss : 0.7180  total_loss : 11.1806  avg_loss_step : 11.1213  learning_rate : 7.5e-07
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 18:23:01.844164 - Iteration: 5  throughput_train : 148.429 seq/s mlm_loss : 10.4286  nsp_loss : 0.6888  total_loss : 11.1174  avg_loss_step : 11.1209  learning_rate : 1.125e-06
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 18:30:37.750790 - Iteration: 6  throughput_train : 148.317 seq/s mlm_loss : 10.4288  nsp_loss : 0.7042  total_loss : 11.1330  avg_loss_step : 11.1203  learning_rate : 1.5e-06
DLL 2020-12-16 18:38:13.612880 - Iteration: 7  throughput_train : 148.331 seq/s mlm_loss : 10.3934  nsp_loss : 0.7218  total_loss : 11.1151  avg_loss_step : 11.1197  learning_rate : 1.8750001e-06
DLL 2020-12-16 18:45:49.410510 - Iteration: 8  throughput_train : 148.352 seq/s mlm_loss : 10.4376  nsp_loss : 0.7066  total_loss : 11.1442  avg_loss_step : 11.1203  learning_rate : 2.25e-06
DLL 2020-12-16 18:54:06.871106 - Iteration: 9  throughput_train : 135.923 seq/s mlm_loss : 10.4258  nsp_loss : 0.7019  total_loss : 11.1276  avg_loss_step : 11.1174  learning_rate : 2.625e-06
DLL 2020-12-16 19:01:43.246759 - Iteration: 10  throughput_train : 148.166 seq/s mlm_loss : 10.4280  nsp_loss : 0.6891  total_loss : 11.1172  avg_loss_step : 11.1170  learning_rate : 3e-06
DLL 2020-12-16 19:09:19.345007 - Iteration: 11  throughput_train : 148.256 seq/s mlm_loss : 10.4368  nsp_loss : 0.7069  total_loss : 11.1436  avg_loss_step : 11.1172  learning_rate : 3.3750002e-06
DLL 2020-12-16 19:16:55.469328 - Iteration: 12  throughput_train : 148.246 seq/s mlm_loss : 10.4026  nsp_loss : 0.6577  total_loss : 11.0603  avg_loss_step : 11.1152  learning_rate : 3.7500001e-06
DLL 2020-12-16 19:24:31.641857 - Iteration: 13  throughput_train : 148.230 seq/s mlm_loss : 10.4181  nsp_loss : 0.7376  total_loss : 11.1557  avg_loss_step : 11.1144  learning_rate : 4.125e-06
DLL 2020-12-16 19:32:07.797857 - Iteration: 14  throughput_train : 148.237 seq/s mlm_loss : 10.4201  nsp_loss : 0.7124  total_loss : 11.1325  avg_loss_step : 11.1123  learning_rate : 4.5e-06
DLL 2020-12-16 19:39:43.683651 - Iteration: 15  throughput_train : 148.324 seq/s mlm_loss : 10.4173  nsp_loss : 0.6912  total_loss : 11.1084  avg_loss_step : 11.1121  learning_rate : 4.8750003e-06
DLL 2020-12-16 19:47:19.394955 - Iteration: 16  throughput_train : 148.382 seq/s mlm_loss : 10.3818  nsp_loss : 0.6781  total_loss : 11.0600  avg_loss_step : 11.1108  learning_rate : 5.25e-06
DLL 2020-12-16 19:54:55.749088 - Iteration: 17  throughput_train : 148.173 seq/s mlm_loss : 10.4319  nsp_loss : 0.6416  total_loss : 11.0735  avg_loss_step : 11.1102  learning_rate : 5.625e-06
DLL 2020-12-16 20:02:31.793985 - Iteration: 18  throughput_train : 148.271 seq/s mlm_loss : 10.4183  nsp_loss : 0.6924  total_loss : 11.1106  avg_loss_step : 11.1080  learning_rate : 6e-06
DLL 2020-12-16 20:10:07.752883 - Iteration: 19  throughput_train : 148.301 seq/s mlm_loss : 10.4130  nsp_loss : 0.7164  total_loss : 11.1294  avg_loss_step : 11.1060  learning_rate : 6.3750003e-06
DLL 2020-12-16 20:17:44.036146 - Iteration: 20  throughput_train : 148.195 seq/s mlm_loss : 10.4040  nsp_loss : 0.6354  total_loss : 11.0394  avg_loss_step : 11.1045  learning_rate : 6.7500005e-06
DLL 2020-12-16 20:25:20.604727 - Iteration: 21  throughput_train : 148.102 seq/s mlm_loss : 10.4068  nsp_loss : 0.6915  total_loss : 11.0983  avg_loss_step : 11.1024  learning_rate : 7.125e-06
DLL 2020-12-16 20:32:56.627262 - Iteration: 22  throughput_train : 148.279 seq/s mlm_loss : 10.4189  nsp_loss : 0.6830  total_loss : 11.1019  avg_loss_step : 11.1019  learning_rate : 7.5000003e-06
DLL 2020-12-16 20:40:32.807151 - Iteration: 23  throughput_train : 148.228 seq/s mlm_loss : 10.4069  nsp_loss : 0.7048  total_loss : 11.1117  avg_loss_step : 11.0985  learning_rate : 7.875e-06
DLL 2020-12-16 20:48:08.902354 - Iteration: 24  throughput_train : 148.254 seq/s mlm_loss : 10.3874  nsp_loss : 0.7264  total_loss : 11.1138  avg_loss_step : 11.0966  learning_rate : 8.25e-06
DLL 2020-12-16 20:55:44.670333 - Iteration: 25  throughput_train : 148.363 seq/s mlm_loss : 10.4242  nsp_loss : 0.6674  total_loss : 11.0916  avg_loss_step : 11.0952  learning_rate : 8.625e-06
DLL 2020-12-16 21:03:20.717131 - Iteration: 26  throughput_train : 148.272 seq/s mlm_loss : 10.4100  nsp_loss : 0.6631  total_loss : 11.0731  avg_loss_step : 11.0909  learning_rate : 9e-06
DLL 2020-12-16 21:10:56.640067 - Iteration: 27  throughput_train : 148.311 seq/s mlm_loss : 10.4072  nsp_loss : 0.6994  total_loss : 11.1066  avg_loss_step : 11.0891  learning_rate : 9.375e-06
DLL 2020-12-16 21:18:32.435337 - Iteration: 28  throughput_train : 148.353 seq/s mlm_loss : 10.4260  nsp_loss : 0.6860  total_loss : 11.1120  avg_loss_step : 11.0859  learning_rate : 9.750001e-06
DLL 2020-12-16 21:26:08.475802 - Iteration: 29  throughput_train : 148.273 seq/s mlm_loss : 10.3797  nsp_loss : 0.6713  total_loss : 11.0510  avg_loss_step : 11.0823  learning_rate : 1.0125001e-05
DLL 2020-12-16 21:33:44.716798 - Iteration: 30  throughput_train : 148.209 seq/s mlm_loss : 10.4257  nsp_loss : 0.7067  total_loss : 11.1324  avg_loss_step : 11.0796  learning_rate : 1.05e-05
DLL 2020-12-16 21:41:21.157350 - Iteration: 31  throughput_train : 148.144 seq/s mlm_loss : 10.4288  nsp_loss : 0.6400  total_loss : 11.0688  avg_loss_step : 11.0774  learning_rate : 1.0875e-05
DLL 2020-12-16 21:48:57.522477 - Iteration: 32  throughput_train : 148.167 seq/s mlm_loss : 10.4147  nsp_loss : 0.7074  total_loss : 11.1221  avg_loss_step : 11.0734  learning_rate : 1.125e-05
DLL 2020-12-16 21:56:33.786528 - Iteration: 33  throughput_train : 148.201 seq/s mlm_loss : 10.3794  nsp_loss : 0.6824  total_loss : 11.0618  avg_loss_step : 11.0714  learning_rate : 1.1625e-05
DLL 2020-12-16 22:04:09.797793 - Iteration: 34  throughput_train : 148.284 seq/s mlm_loss : 10.3797  nsp_loss : 0.6998  total_loss : 11.0795  avg_loss_step : 11.0673  learning_rate : 1.2e-05
DLL 2020-12-16 22:11:46.140040 - Iteration: 35  throughput_train : 148.176 seq/s mlm_loss : 10.4093  nsp_loss : 0.6959  total_loss : 11.1052  avg_loss_step : 11.0645  learning_rate : 1.2375001e-05
DLL 2020-12-16 22:19:22.146424 - Iteration: 36  throughput_train : 148.285 seq/s mlm_loss : 10.3630  nsp_loss : 0.6950  total_loss : 11.0580  avg_loss_step : 11.0599  learning_rate : 1.2750001e-05
DLL 2020-12-16 22:26:58.216577 - Iteration: 37  throughput_train : 148.263 seq/s mlm_loss : 10.3804  nsp_loss : 0.7208  total_loss : 11.1012  avg_loss_step : 11.0582  learning_rate : 1.3125001e-05
DLL 2020-12-16 22:34:34.026107 - Iteration: 38  throughput_train : 148.350 seq/s mlm_loss : 10.3487  nsp_loss : 0.6753  total_loss : 11.0240  avg_loss_step : 11.0521  learning_rate : 1.3500001e-05
DLL 2020-12-16 22:42:10.433085 - Iteration: 39  throughput_train : 148.153 seq/s mlm_loss : 10.3659  nsp_loss : 0.6807  total_loss : 11.0467  avg_loss_step : 11.0487  learning_rate : 1.3875e-05
DLL 2020-12-16 22:49:46.519696 - Iteration: 40  throughput_train : 148.259 seq/s mlm_loss : 10.3832  nsp_loss : 0.7008  total_loss : 11.0839  avg_loss_step : 11.0453  learning_rate : 1.425e-05
DLL 2020-12-16 22:57:22.968774 - Iteration: 41  throughput_train : 148.141 seq/s mlm_loss : 10.3621  nsp_loss : 0.6896  total_loss : 11.0516  avg_loss_step : 11.0416  learning_rate : 1.4625e-05 INFO:tensorflow:loss = 10.99967, step = 42 (3239.874 sec)
I1216 23:17:15.580139 140149878220608 basic_session_run_hooks.py:260] loss = 10.99967, step = 42 (3239.874 sec)
INFO:tensorflow:loss = 10.984088, step = 49 (3239.915 sec)
I1217 00:11:15.495163 140149878220608 basic_session_run_hooks.py:260] loss = 10.984088, step = 49 (3239.915 sec)
INFO:tensorflow:Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1/model.ckpt.
I1217 00:13:25.256053 140149878220608 basic_session_run_hooks.py:606] Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 10.985448.
I1217 00:13:30.957797 140149878220608 estimator.py:371] Loss for final step: 10.985448.
INFO:tensorflow:-----------------------------
I1217 00:13:30.959589 140149878220608 run_pretraining.py:642] -----------------------------
INFO:tensorflow:Total Training Time = 23028.65 for Sentences = 3379200
I1217 00:13:30.959729 140149878220608 run_pretraining.py:644] Total Training Time = 23028.65 for Sentences = 3379200
INFO:tensorflow:Total Training Time W/O Overhead = 20556.13 for Sentences = 3041280
I1217 00:13:30.959862 140149878220608 run_pretraining.py:646] Total Training Time W/O Overhead = 20556.13 for Sentences = 3041280
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 146.74
I1217 00:13:30.959963 140149878220608 run_pretraining.py:647] Throughput Average (sentences/sec) with overhead = 146.74
INFO:tensorflow:Throughput Average (sentences/sec) = 147.95
I1217 00:13:30.960072 140149878220608 run_pretraining.py:648] Throughput Average (sentences/sec) = 147.95
INFO:tensorflow:-----------------------------
I1217 00:13:30.960344 140149878220608 run_pretraining.py:650] -----------------------------
INFO:tensorflow:***** Running evaluation *****
I1217 00:13:30.960489 140149878220608 run_pretraining.py:653] ***** Running evaluation *****
INFO:tensorflow:  Batch size = 8
I1217 00:13:30.960591 140149878220608 run_pretraining.py:654]   Batch size = 8
INFO:tensorflow:Calling model_fn.
I1217 00:13:31.005893 140149878220608 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1217 00:13:31.006154 140149878220608 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 128)
I1217 00:13:31.006334 140149878220608 run_pretraining.py:259]   name = input_ids, shape = (?, 128)
INFO:tensorflow:  name = input_mask, shape = (?, 128)
I1217 00:13:31.006469 140149878220608 run_pretraining.py:259]   name = input_mask, shape = (?, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (?, 20)
I1217 00:13:31.006590 140149878220608 run_pretraining.py:259]   name = masked_lm_ids, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (?, 20)
I1217 00:13:31.006707 140149878220608 run_pretraining.py:259]   name = masked_lm_positions, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (?, 20)
I1217 00:13:31.006830 140149878220608 run_pretraining.py:259]   name = masked_lm_weights, shape = (?, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (?, 1)
I1217 00:13:31.006946 140149878220608 run_pretraining.py:259]   name = next_sentence_labels, shape = (?, 1)
INFO:tensorflow:  name = segment_ids, shape = (?, 128)
I1217 00:13:31.007068 140149878220608 run_pretraining.py:259]   name = segment_ids, shape = (?, 128)
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

W1217 00:13:32.710066 140149878220608 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W1217 00:13:32.757580 140149878220608 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

INFO:tensorflow:Done calling model_fn.
I1217 00:13:32.829482 140149878220608 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-12-17T00:13:32Z
I1217 00:13:32.845945 140149878220608 evaluation.py:255] Starting evaluation at 2020-12-17T00:13:32Z
INFO:tensorflow:Graph was finalized.
I1217 00:13:33.288565 140149878220608 monitored_session.py:240] Graph was finalized.
2020-12-17 00:13:33.289693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 00:13:33.290841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0b.0
2020-12-17 00:13:33.290962: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-17 00:13:33.291097: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-17 00:13:33.291137: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-17 00:13:33.291176: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-17 00:13:33.291215: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-17 00:13:33.291252: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-17 00:13:33.291312: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-17 00:13:33.291431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 00:13:33.292962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 00:13:33.294003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-17 00:13:33.294059: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-17 00:13:33.294079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-17 00:13:33.294098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-17 00:13:33.294243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 00:13:33.295324: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-17 00:13:33.296347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14799 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0)
INFO:tensorflow:Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1/model.ckpt-50
I1217 00:13:33.297363 140149878220608 saver.py:1284] Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1/model.ckpt-50
INFO:tensorflow:Running local_init_op.
I1217 00:13:34.420582 140149878220608 session_manager.py:500] Running local_init_op.
INFO:tensorflow:Done running local_init_op.
I1217 00:13:34.579668 140149878220608 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Evaluation [10/100]
I1217 00:13:41.616015 140149878220608 evaluation.py:167] Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
I1217 00:13:41.839304 140149878220608 evaluation.py:167] Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
I1217 00:13:42.061706 140149878220608 evaluation.py:167] Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
I1217 00:13:42.291902 140149878220608 evaluation.py:167] Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
I1217 00:13:42.518215 140149878220608 evaluation.py:167] Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
I1217 00:13:42.745136 140149878220608 evaluation.py:167] Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
I1217 00:13:42.969683 140149878220608 evaluation.py:167] Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
I1217 00:13:43.190962 140149878220608 evaluation.py:167] Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
I1217 00:13:43.414412 140149878220608 evaluation.py:167] Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
I1217 00:13:43.636494 140149878220608 evaluation.py:167] Evaluation [100/100]
INFO:tensorflow:Finished evaluation at 2020-12-17-00:13:44
I1217 00:13:44.002818 140149878220608 evaluation.py:275] Finished evaluation at 2020-12-17-00:13:44
INFO:tensorflow:Saving dict for global step 50: global_step = 50, loss = 10.98672, masked_lm_accuracy = 6.776905e-05, masked_lm_loss = 10.288882, next_sentence_accuracy = 0.53, next_sentence_loss = 0.69793725
I1217 00:13:44.003513 140149878220608 estimator.py:2049] Saving dict for global step 50: global_step = 50, loss = 10.98672, masked_lm_accuracy = 6.776905e-05, masked_lm_loss = 10.288882, next_sentence_accuracy = 0.53, next_sentence_loss = 0.69793725
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1/model.ckpt-50
I1217 00:13:44.419414 140149878220608 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp32_gbs167584_gbs232768_201216174939/phase_1/model.ckpt-50
INFO:tensorflow:-----------------------------
I1217 00:13:44.420549 140149878220608 run_pretraining.py:682] -----------------------------
INFO:tensorflow:Total Inference Time = 13.46 for Sentences = 800
I1217 00:13:44.420745 140149878220608 run_pretraining.py:684] Total Inference Time = 13.46 for Sentences = 800
INFO:tensorflow:Total Inference Time W/O Overhead = 2.22 for Sentences = 792
I1217 00:13:44.420917 140149878220608 run_pretraining.py:686] Total Inference Time W/O Overhead = 2.22 for Sentences = 792
INFO:tensorflow:Summary Inference Statistics on EVAL set
I1217 00:13:44.421017 140149878220608 run_pretraining.py:687] Summary Inference Statistics on EVAL set
INFO:tensorflow:Batch size = 8
I1217 00:13:44.421115 140149878220608 run_pretraining.py:688] Batch size = 8
INFO:tensorflow:Sequence Length = 128
I1217 00:13:44.421252 140149878220608 run_pretraining.py:689] Sequence Length = 128
INFO:tensorflow:Precision = fp32
I1217 00:13:44.421368 140149878220608 run_pretraining.py:690] Precision = fp32
INFO:tensorflow:Throughput Average (sentences/sec) = 357.19
I1217 00:13:44.421464 140149878220608 run_pretraining.py:691] Throughput Average (sentences/sec) = 357.19
INFO:tensorflow:-----------------------------
I1217 00:13:44.421780 140149878220608 run_pretraining.py:693] -----------------------------
INFO:tensorflow:***** Eval results *****
I1217 00:13:44.421954 140149878220608 run_pretraining.py:697] ***** Eval results *****
INFO:tensorflow:  global_step = 50
I1217 00:13:44.422062 140149878220608 run_pretraining.py:699]   global_step = 50
INFO:tensorflow:  loss = 10.98672
I1217 00:13:44.422378 140149878220608 run_pretraining.py:699]   loss = 10.98672
INFO:tensorflow:  masked_lm_accuracy = 6.776905e-05
I1217 00:13:44.422516 140149878220608 run_pretraining.py:699]   masked_lm_accuracy = 6.776905e-05
INFO:tensorflow:  masked_lm_loss = 10.288882
I1217 00:13:44.422626 140149878220608 run_pretraining.py:699]   masked_lm_loss = 10.288882
INFO:tensorflow:  next_sentence_accuracy = 0.53
I1217 00:13:44.422726 140149878220608 run_pretraining.py:699]   next_sentence_accuracy = 0.53
INFO:tensorflow:  next_sentence_loss = 0.69793725
I1217 00:13:44.422822 140149878220608 run_pretraining.py:699]   next_sentence_loss = 0.69793725

DLL 2020-12-16 23:04:59.196149 - Iteration: 42  throughput_train : 148.212 seq/s mlm_loss : 10.3486  nsp_loss : 0.6571  total_loss : 11.0058  avg_loss_step : 11.0370  learning_rate : 1.50000005e-05
DLL 2020-12-16 23:12:35.368550 - Iteration: 43  throughput_train : 148.231 seq/s mlm_loss : 10.3729  nsp_loss : 0.6793  total_loss : 11.0523  avg_loss_step : 11.0320  learning_rate : 1.5375e-05
DLL 2020-12-16 23:20:11.295492 - Iteration: 44  throughput_train : 148.311 seq/s mlm_loss : 10.3290  nsp_loss : 0.6696  total_loss : 10.9987  avg_loss_step : 11.0273  learning_rate : 1.575e-05
DLL 2020-12-16 23:27:47.022063 - Iteration: 45  throughput_train : 148.377 seq/s mlm_loss : 10.3551  nsp_loss : 0.6738  total_loss : 11.0289  avg_loss_step : 11.0239  learning_rate : 1.6125001e-05
DLL 2020-12-16 23:35:22.831559 - Iteration: 46  throughput_train : 148.350 seq/s mlm_loss : 10.3488  nsp_loss : 0.7001  total_loss : 11.0489  avg_loss_step : 11.0196  learning_rate : 1.65e-05
DLL 2020-12-16 23:42:59.237435 - Iteration: 47  throughput_train : 148.154 seq/s mlm_loss : 10.3579  nsp_loss : 0.6859  total_loss : 11.0438  avg_loss_step : 11.0133  learning_rate : 1.6875001e-05
DLL 2020-12-16 23:50:35.429363 - Iteration: 48  throughput_train : 148.225 seq/s mlm_loss : 10.3163  nsp_loss : 0.7037  total_loss : 11.0201  avg_loss_step : 11.0099  learning_rate : 1.725e-05
DLL 2020-12-16 23:58:11.619816 - Iteration: 49  throughput_train : 148.223 seq/s mlm_loss : 10.3109  nsp_loss : 0.6985  total_loss : 11.0094  avg_loss_step : 11.0037  learning_rate : 1.7625001e-05
DLL 2020-12-17 00:05:47.831232 - Iteration: 50  throughput_train : 148.219 seq/s mlm_loss : 10.2994  nsp_loss : 0.6749  total_loss : 10.9743  avg_loss_step : 10.9996  learning_rate : 1.8e-05
DLL 2020-12-17 00:13:25.254336 - Iteration: 51  throughput_train : 148.088 seq/s mlm_loss : 10.3223  nsp_loss : 0.6632  total_loss : 10.9854  avg_loss_step : 10.9932  learning_rate : 1.8375e-05
DLL 2020-12-17 00:13:30.960176 -  throughput_train : 147.950 seq/s
DLL 2020-12-17 00:13:44.421582 -  throughput_val : 357.190074600602
