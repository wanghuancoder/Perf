Container nvidia build =  13409399
XLA activated
2020-12-16 15:37:16.612886: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:152: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod-0.19.1-py3.6-linux-x86_64.egg/horovod/tensorflow/__init__.py:178: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

W1216 15:37:18.302063 140185970218816 lazy_loader.py:50]
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

W1216 15:37:19.038811 140185970218816 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:587: The name tf.enable_resource_variables is deprecated. Please use tf.compat.v1.enable_resource_variables instead.

INFO:tensorflow:Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7dfe8f1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
I1216 15:37:19.039734 140185970218816 estimator.py:212] Using config: {'_model_dir': '/results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1', '_tf_random_seed': None, '_save_summary_steps': 200, '_save_checkpoints_steps': 200, '_save_checkpoints_secs': None, '_session_config': graph_options {
  optimizer_options {
    global_jit_level: ON_1
  }
  rewrite_options {
    memory_optimization: NO_MEM_OPT
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 10000, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7dfe8f1e80>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f7dfe8f5bf8>) includes params argument, but params are not passed to Estimator.
W1216 15:37:19.040624 140185970218816 model_fn.py:630] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f7dfe8f5bf8>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:***** Running training *****
I1216 15:37:19.041257 140185970218816 run_pretraining.py:623] ***** Running training *****
INFO:tensorflow:  Batch size = 64
I1216 15:37:19.041391 140185970218816 run_pretraining.py:624]   Batch size = 64
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

W1216 15:37:19.163021 140185970218816 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.

INFO:tensorflow:Calling model_fn.
I1216 15:37:19.293444 140185970218816 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1216 15:37:19.293732 140185970218816 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (64, 128)
I1216 15:37:19.293989 140185970218816 run_pretraining.py:259]   name = input_ids, shape = (64, 128)
INFO:tensorflow:  name = input_mask, shape = (64, 128)
I1216 15:37:19.294174 140185970218816 run_pretraining.py:259]   name = input_mask, shape = (64, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (64, 20)
I1216 15:37:19.294322 140185970218816 run_pretraining.py:259]   name = masked_lm_ids, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (64, 20)
I1216 15:37:19.294486 140185970218816 run_pretraining.py:259]   name = masked_lm_positions, shape = (64, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (64, 20)
I1216 15:37:19.294618 140185970218816 run_pretraining.py:259]   name = masked_lm_weights, shape = (64, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (64, 1)
I1216 15:37:19.294731 140185970218816 run_pretraining.py:259]   name = next_sentence_labels, shape = (64, 1)
INFO:tensorflow:  name = segment_ids, shape = (64, 128)
I1216 15:37:19.294842 140185970218816 run_pretraining.py:259]   name = segment_ids, shape = (64, 128)
WARNING:tensorflow:From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W1216 15:37:19.295114 140185970218816 module_wrapper.py:139] From /workspace/bert/modeling.py:176: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

W1216 15:37:19.296659 140185970218816 module_wrapper.py:139] From /workspace/bert/modeling.py:427: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

W1216 15:37:21.365978 140185970218816 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:295: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

W1216 15:37:25.295665 140185970218816 module_wrapper.py:139] From /workspace/bert/optimization.py:130: The name tf.is_finite is deprecated. Please use tf.math.is_finite instead.

WARNING:tensorflow:From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

W1216 15:37:25.595530 140185970218816 module_wrapper.py:139] From /workspace/bert/optimization.py:142: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.

INFO:tensorflow:Done calling model_fn.
I1216 15:37:36.936649 140185970218816 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
I1216 15:37:36.938192 140185970218816 basic_session_run_hooks.py:541] Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
I1216 15:37:41.701822 140185970218816 monitored_session.py:240] Graph was finalized.
2020-12-16 15:37:41.711772: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2399970000 Hz
2020-12-16 15:37:41.714104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18123730 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-16 15:37:41.714159: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-16 15:37:41.717107: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-12-16 15:37:42.061210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 15:37:42.065126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xac46720 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-16 15:37:42.065189: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-16GB, Compute Capability 7.0
2020-12-16 15:37:42.065536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 15:37:42.069180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0b.0
2020-12-16 15:37:42.069256: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-16 15:37:42.072747: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-16 15:37:42.074289: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-16 15:37:42.074665: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-16 15:37:42.077603: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-16 15:37:42.078269: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-16 15:37:42.078533: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-16 15:37:42.078671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 15:37:42.086192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 15:37:42.089813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-16 15:37:42.089879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-16 15:37:42.952889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-16 15:37:42.953010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-16 15:37:42.953037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-16 15:37:42.953405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 15:37:42.954856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 15:37:42.957364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14799 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0)
2020-12-16 15:37:46.854919: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:37:46.869072: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 15:37:49.754092: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1648] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-12-16 15:37:54.024857: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:37:54.033005: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1216 15:37:54.886987 140185970218816 session_manager.py:500] Running local_init_op.
2020-12-16 15:37:55.448780: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:37:55.449127: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1216 15:37:55.584171 140185970218816 session_manager.py:502] Done running local_init_op.
2020-12-16 15:37:56.312749: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:37:56.320829: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 15:37:57.801400: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:37:57.801835: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1/model.ckpt.
I1216 15:38:08.089844 140185970218816 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1/model.ckpt.
2020-12-16 15:38:09.058923: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:38:09.069329: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 15:38:16.612236: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:38:16.612764: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 15:38:16.617975: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 15:38:16.620387: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 15:38:16.624158: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

W1216 15:38:16.854076 140185970218816 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:146: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.

2020-12-16 15:38:17.476597: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:38:17.476990: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 15:38:32.308384: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:38:32.512213: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 24313
Recognized nodes available for conversion: 15663
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


2020-12-16 15:38:46.608706: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-16 15:38:47.416998: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-16 15:39:23.588115: I tensorflow/compiler/jit/xla_compilation_cache.cc:243] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
INFO:tensorflow:loss = 11.141301, step = 0
I1216 15:39:25.664266 140185970218816 basic_session_run_hooks.py:262] loss = 11.141301, step = 0
2020-12-16 15:39:40.683449: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 15:39:40.888964: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 24313
Recognized nodes available for conversion: 15663
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 15:40:30.368287 140185970218816 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 15:40:30.504706 140185970218816 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 15:40:30.633996 140185970218816 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 15:40:30.762175 140185970218816 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
W1216 15:40:30.889299 140185970218816 basic_session_run_hooks.py:724] It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
2020-12-16 16:03:08.332925: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 16:03:08.530323: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 24313
Recognized nodes available for conversion: 15663
Total nodes converted: 599
Total FP16 Cast ops used (excluding Const and Variable casts): 102
Whitelisted nodes converted: 300
Blacklisted nodes blocking conversion: 1401
Nodes blocked from conversion by blacklisted nodes: 4428

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


INFO:tensorflow:loss = 11.161823, step = 4 (1476.140 sec)
I1216 16:04:01.804114 140185970218816 basic_session_run_hooks.py:260] loss = 11.161823, step = 4 (1476.140 sec)
INFO:tensorflow:loss = 11.126016, step = 13 (1313.835 sec)
I1216 16:25:55.638660 140185970218816 basic_session_run_hooks.py:260] loss = 11.126016, step = 13 (1313.835 sec)
INFO:tensorflow:loss = 11.113583, step = 23 (1315.571 sec)
I1216 16:47:51.210083 140185970218816 basic_session_run_hooks.py:260] loss = 11.113583, step = 23 (1315.571 sec)
decayed_learning_rate_at_crossover_point = 7.500000e-04, adjusted_init_lr = 7.500000e-04
Initializing LAMB Optimizer
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 15:42:51.335292 - Iteration: 1  throughput_train : 247.109 seq/s mlm_loss : 10.4511  nsp_loss : 0.6911  total_loss : 11.1422  avg_loss_step : 11.1508  learning_rate : 0.0  loss_scaler : 4294967296
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 15:45:06.037203 - Iteration: 1  throughput_train : 502.294 seq/s mlm_loss : 10.4733  nsp_loss : 0.6924  total_loss : 11.1657  avg_loss_step : 11.1511  learning_rate : 0.0  loss_scaler : 2147483648
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 15:47:21.490942 - Iteration: 1  throughput_train : 499.516 seq/s mlm_loss : 10.4356  nsp_loss : 0.6913  total_loss : 11.1270  avg_loss_step : 11.1512  learning_rate : 0.0  loss_scaler : 1073741824
Skipping time record for  0  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 15:49:42.829470 - Iteration: 1  throughput_train : 478.705 seq/s mlm_loss : 10.4601  nsp_loss : 0.6890  total_loss : 11.1491  avg_loss_step : 11.1509  learning_rate : 0.0  loss_scaler : 536870912
Skipping time record for  1  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 15:52:33.966978 - Iteration: 2  throughput_train : 395.267 seq/s mlm_loss : 10.4699  nsp_loss : 0.7014  total_loss : 11.1713  avg_loss_step : 11.1508  learning_rate : 0.0  loss_scaler : 268435456
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 15:54:52.097731 - Iteration: 3  throughput_train : 489.816 seq/s mlm_loss : 10.4527  nsp_loss : 0.6917  total_loss : 11.1444  avg_loss_step : 11.1513  learning_rate : 3.75e-07  loss_scaler : 268435456
Skipping time record for  2  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 15:57:10.705788 - Iteration: 3  throughput_train : 488.141 seq/s mlm_loss : 10.4692  nsp_loss : 0.6983  total_loss : 11.1675  avg_loss_step : 11.1515  learning_rate : 7.5e-07  loss_scaler : 268435456
Skipping time record for  3  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 15:59:29.383512 - Iteration: 4  throughput_train : 487.889 seq/s mlm_loss : 10.4521  nsp_loss : 0.6953  total_loss : 11.1473  avg_loss_step : 11.1501  learning_rate : 7.5e-07  loss_scaler : 134217728
Skipping time record for  4  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 16:01:47.872656 - Iteration: 5  throughput_train : 488.553 seq/s mlm_loss : 10.4767  nsp_loss : 0.7071  total_loss : 11.1838  avg_loss_step : 11.1503  learning_rate : 1.125e-06  loss_scaler : 134217728
Skipping time record for  5  due to checkpoint-saving/warmup overhead
DLL 2020-12-16 16:05:14.737245 - Iteration: 6  throughput_train : 326.950 seq/s mlm_loss : 10.4354  nsp_loss : 0.6826  total_loss : 11.1180  avg_loss_step : 11.1500  learning_rate : 1.5e-06  loss_scaler : 134217728
DLL 2020-12-16 16:07:33.248638 - Iteration: 7  throughput_train : 488.461 seq/s mlm_loss : 10.4680  nsp_loss : 0.7044  total_loss : 11.1724  avg_loss_step : 11.1505  learning_rate : 1.8750001e-06  loss_scaler : 134217728
DLL 2020-12-16 16:09:51.708703 - Iteration: 8  throughput_train : 488.662 seq/s mlm_loss : 10.4643  nsp_loss : 0.6977  total_loss : 11.1620  avg_loss_step : 11.1487  learning_rate : 2.25e-06  loss_scaler : 134217728
DLL 2020-12-16 16:12:10.667083 - Iteration: 9  throughput_train : 486.901 seq/s mlm_loss : 10.4389  nsp_loss : 0.7037  total_loss : 11.1425  avg_loss_step : 11.1487  learning_rate : 2.625e-06  loss_scaler : 134217728
DLL 2020-12-16 16:14:29.592072 - Iteration: 10  throughput_train : 487.011 seq/s mlm_loss : 10.4428  nsp_loss : 0.6952  total_loss : 11.1380  avg_loss_step : 11.1473  learning_rate : 3e-06  loss_scaler : 134217728
DLL 2020-12-16 16:16:48.358646 - Iteration: 11  throughput_train : 487.570 seq/s mlm_loss : 10.4515  nsp_loss : 0.6881  total_loss : 11.1396  avg_loss_step : 11.1467  learning_rate : 3.3750002e-06  loss_scaler : 134217728
DLL 2020-12-16 16:19:07.490795 - Iteration: 12  throughput_train : 486.291 seq/s mlm_loss : 10.4648  nsp_loss : 0.6914  total_loss : 11.1562  avg_loss_step : 11.1446  learning_rate : 3.7500001e-06  loss_scaler : 134217728
DLL 2020-12-16 16:21:26.371437 - Iteration: 13  throughput_train : 487.189 seq/s mlm_loss : 10.4692  nsp_loss : 0.7068  total_loss : 11.1761  avg_loss_step : 11.1448  learning_rate : 4.125e-06  loss_scaler : 134217728
DLL 2020-12-16 16:23:45.345310 - Iteration: 14  throughput_train : 486.845 seq/s mlm_loss : 10.4372  nsp_loss : 0.6826  total_loss : 11.1198  avg_loss_step : 11.1439  learning_rate : 4.5e-06  loss_scaler : 134217728
DLL 2020-12-16 16:26:03.940909 - Iteration: 15  throughput_train : 488.169 seq/s mlm_loss : 10.4317  nsp_loss : 0.7002  total_loss : 11.1319  avg_loss_step : 11.1423  learning_rate : 4.8750003e-06  loss_scaler : 134217728
DLL 2020-12-16 16:28:22.827186 - Iteration: 16  throughput_train : 487.142 seq/s mlm_loss : 10.4421  nsp_loss : 0.6953  total_loss : 11.1375  avg_loss_step : 11.1397  learning_rate : 5.25e-06  loss_scaler : 134217728
DLL 2020-12-16 16:30:41.863542 - Iteration: 17  throughput_train : 486.626 seq/s mlm_loss : 10.4497  nsp_loss : 0.7111  total_loss : 11.1608  avg_loss_step : 11.1385  learning_rate : 5.625e-06  loss_scaler : 134217728
DLL 2020-12-16 16:33:00.880669 - Iteration: 18  throughput_train : 486.690 seq/s mlm_loss : 10.4343  nsp_loss : 0.7029  total_loss : 11.1371  avg_loss_step : 11.1355  learning_rate : 6e-06  loss_scaler : 134217728
DLL 2020-12-16 16:35:19.858996 - Iteration: 19  throughput_train : 486.830 seq/s mlm_loss : 10.4559  nsp_loss : 0.6804  total_loss : 11.1363  avg_loss_step : 11.1340  learning_rate : 6.3750003e-06  loss_scaler : 134217728
DLL 2020-12-16 16:37:38.870611 - Iteration: 20  throughput_train : 486.719 seq/s mlm_loss : 10.4378  nsp_loss : 0.6867  total_loss : 11.1244  avg_loss_step : 11.1320  learning_rate : 6.7500005e-06  loss_scaler : 134217728
DLL 2020-12-16 16:39:57.910399 - Iteration: 21  throughput_train : 486.619 seq/s mlm_loss : 10.4367  nsp_loss : 0.6778  total_loss : 11.1145  avg_loss_step : 11.1304  learning_rate : 7.125e-06  loss_scaler : 134217728
DLL 2020-12-16 16:42:16.681549 - Iteration: 22  throughput_train : 487.548 seq/s mlm_loss : 10.4325  nsp_loss : 0.6849  total_loss : 11.1175  avg_loss_step : 11.1281  learning_rate : 7.5000003e-06  loss_scaler : 134217728
DLL 2020-12-16 16:44:35.447031 - Iteration: 23  throughput_train : 487.574 seq/s mlm_loss : 10.4384  nsp_loss : 0.7059  total_loss : 11.1443  avg_loss_step : 11.1252  learning_rate : 7.875e-06  loss_scaler : 134217728
DLL 2020-12-16 16:46:54.242728 - Iteration: 24  throughput_train : 487.468 seq/s mlm_loss : 10.4199  nsp_loss : 0.6947  total_loss : 11.1145  avg_loss_step : 11.1228  learning_rate : 8.25e-06  loss_scaler : 134217728
DLL 2020-12-16 16:49:13.072016 - Iteration: 25  throughput_train : 487.360 seq/s mlm_loss : 10.4088  nsp_loss : 0.6891  total_loss : 11.0979  avg_loss_step : 11.1210  learning_rate : 8.625e-06  loss_scaler : 134217728
DLL 2020-12-16 16:51:31.938910 - Iteration: 26  throughput_train : 487.237 seq/s mlm_loss : 10.4330  nsp_loss : 0.6973  total_loss : 11.1303  avg_loss_step : 11.1179  learning_rate : 9e-06  loss_scaler : 134217728
DLL 2020-12-16 16:53:50.405552 - Iteration: 27  throughput_train : 488.645 seq/s mlm_loss : 10.4615  nsp_loss : 0.6750  total_loss : 11.1365  avg_loss_step : 11.1157  learning_rate : 9.375e-06  loss_scaler : 134217728
DLL 2020-12-16 16:56:09.111901 - Iteration: 28  throughput_train : 487.787 seq/s mlm_loss : 10.4262  nsp_loss : 0.7146  total_loss : 11.1408  avg_loss_step : 11.1131  learning_rate : 9.750001e-06  loss_scaler : 134217728
DLL 2020-12-16 16:58:27.633137 - Iteration: 29  throughput_train : 488.425 seq/s mlm_loss : 10.4174  nsp_loss : 0.6866  total_loss : 11.1040  avg_loss_step : 11.1099  learning_rate : 1.0125001e-05  loss_scaler : 134217728
DLL 2020-12-16 17:00:46.208481 - Iteration: 30  throughput_train : 488.261 seq/s mlm_loss : 10.4277  nsp_loss : 0.6910  total_loss : 11.1187  avg_loss_step : 11.1081  learning_rate : 1.05e-05  loss_scaler : 134217728 INFO:tensorflow:loss = 11.081704, step = 32 (1313.326 sec)
I1216 17:09:44.536439 140185970218816 basic_session_run_hooks.py:260] loss = 11.081704, step = 32 (1313.326 sec)
INFO:tensorflow:loss = 11.004784, step = 42 (1313.273 sec)
I1216 17:31:37.809383 140185970218816 basic_session_run_hooks.py:260] loss = 11.004784, step = 42 (1313.273 sec)
INFO:tensorflow:Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1/model.ckpt.
I1216 17:49:16.202692 140185970218816 basic_session_run_hooks.py:606] Saving checkpoints for 50 into /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1/model.ckpt.
INFO:tensorflow:Loss for final step: 11.045477.
I1216 17:49:22.325799 140185970218816 estimator.py:371] Loss for final step: 11.045477.
INFO:tensorflow:-----------------------------
I1216 17:49:22.327217 140185970218816 run_pretraining.py:642] -----------------------------
INFO:tensorflow:Total Training Time = 7923.29 for Sentences = 3379200
I1216 17:49:22.327385 140185970218816 run_pretraining.py:644] Total Training Time = 7923.29 for Sentences = 3379200
INFO:tensorflow:Total Training Time W/O Overhead = 6234.18 for Sentences = 2703360
I1216 17:49:22.327510 140185970218816 run_pretraining.py:646] Total Training Time W/O Overhead = 6234.18 for Sentences = 2703360
INFO:tensorflow:Throughput Average (sentences/sec) with overhead = 426.49
I1216 17:49:22.327616 140185970218816 run_pretraining.py:647] Throughput Average (sentences/sec) with overhead = 426.49
INFO:tensorflow:Throughput Average (sentences/sec) = 433.64
I1216 17:49:22.327726 140185970218816 run_pretraining.py:648] Throughput Average (sentences/sec) = 433.64
INFO:tensorflow:-----------------------------
I1216 17:49:22.327986 140185970218816 run_pretraining.py:650] -----------------------------
INFO:tensorflow:***** Running evaluation *****
I1216 17:49:22.328111 140185970218816 run_pretraining.py:653] ***** Running evaluation *****
INFO:tensorflow:  Batch size = 8
I1216 17:49:22.328212 140185970218816 run_pretraining.py:654]   Batch size = 8
INFO:tensorflow:Calling model_fn.
I1216 17:49:22.372209 140185970218816 estimator.py:1148] Calling model_fn.
INFO:tensorflow:*** Features ***
I1216 17:49:22.372486 140185970218816 run_pretraining.py:257] *** Features ***
INFO:tensorflow:  name = input_ids, shape = (?, 128)
I1216 17:49:22.372648 140185970218816 run_pretraining.py:259]   name = input_ids, shape = (?, 128)
INFO:tensorflow:  name = input_mask, shape = (?, 128)
I1216 17:49:22.372778 140185970218816 run_pretraining.py:259]   name = input_mask, shape = (?, 128)
INFO:tensorflow:  name = masked_lm_ids, shape = (?, 20)
I1216 17:49:22.372899 140185970218816 run_pretraining.py:259]   name = masked_lm_ids, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_positions, shape = (?, 20)
I1216 17:49:22.373015 140185970218816 run_pretraining.py:259]   name = masked_lm_positions, shape = (?, 20)
INFO:tensorflow:  name = masked_lm_weights, shape = (?, 20)
I1216 17:49:22.373128 140185970218816 run_pretraining.py:259]   name = masked_lm_weights, shape = (?, 20)
INFO:tensorflow:  name = next_sentence_labels, shape = (?, 1)
I1216 17:49:22.373243 140185970218816 run_pretraining.py:259]   name = next_sentence_labels, shape = (?, 1)
INFO:tensorflow:  name = segment_ids, shape = (?, 128)
I1216 17:49:22.373371 140185970218816 run_pretraining.py:259]   name = segment_ids, shape = (?, 128)
WARNING:tensorflow:From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

W1216 17:49:24.961795 140185970218816 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:337: The name tf.metrics.accuracy is deprecated. Please use tf.compat.v1.metrics.accuracy instead.

WARNING:tensorflow:From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

W1216 17:49:25.010973 140185970218816 module_wrapper.py:139] From /workspace/bert/run_pretraining.py:341: The name tf.metrics.mean is deprecated. Please use tf.compat.v1.metrics.mean instead.

INFO:tensorflow:Done calling model_fn.
I1216 17:49:25.089114 140185970218816 estimator.py:1150] Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2020-12-16T17:49:25Z
I1216 17:49:25.109139 140185970218816 evaluation.py:255] Starting evaluation at 2020-12-16T17:49:25Z
INFO:tensorflow:Graph was finalized.
I1216 17:49:25.477023 140185970218816 monitored_session.py:240] Graph was finalized.
2020-12-16 17:49:25.478177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:49:25.480630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties:
name: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53
pciBusID: 0000:00:0b.0
2020-12-16 17:49:25.480752: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.11.0
2020-12-16 17:49:25.480852: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.11
2020-12-16 17:49:25.480897: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-12-16 17:49:25.480932: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-12-16 17:49:25.480969: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-12-16 17:49:25.481003: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.11
2020-12-16 17:49:25.481036: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.8
2020-12-16 17:49:25.481148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:49:25.484214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:49:25.487285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-12-16 17:49:25.487354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-16 17:49:25.487376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0
2020-12-16 17:49:25.487395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N
2020-12-16 17:49:25.487655: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:49:25.490265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-16 17:49:25.496894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14799 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:0b.0, compute capability: 7.0)
INFO:tensorflow:Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1/model.ckpt-50
I1216 17:49:25.497967 140185970218816 saver.py:1284] Restoring parameters from /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1/model.ckpt-50
2020-12-16 17:49:25.687882: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 17:49:25.691242: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 17:49:26.357203: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 17:49:26.359357: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Running local_init_op.
I1216 17:49:26.579623 140185970218816 session_manager.py:500] Running local_init_op.
2020-12-16 17:49:26.636794: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 17:49:26.637301: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Done running local_init_op.
I1216 17:49:26.909091 140185970218816 session_manager.py:502] Done running local_init_op.
2020-12-16 17:49:27.169936: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 17:49:27.172204: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 17:49:27.464445: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 17:49:27.464907: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 17:49:27.470449: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 17:49:27.473484: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
2020-12-16 17:49:27.786142: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 17:49:27.798563: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1035] Automatic Mixed Precision Grappler Pass Summary:

Total processable nodes: 2026
Recognized nodes available for conversion: 1004
Total nodes converted: 276
Total FP16 Cast ops used (excluding Const and Variable casts): 39
Whitelisted nodes converted: 100
Blacklisted nodes blocking conversion: 139
Nodes blocked from conversion by blacklisted nodes: 239

For more information regarding mixed precision training, including how to make automatic mixed precision aware of a custom op type, please see the documentation available here:
https://docs.nvidia.com/deeplearning/frameworks/tensorflow-user-guide/index.html#tfamp


INFO:tensorflow:Evaluation [10/100]
I1216 17:49:35.044747 140185970218816 evaluation.py:167] Evaluation [10/100]
INFO:tensorflow:Evaluation [20/100]
I1216 17:49:35.165839 140185970218816 evaluation.py:167] Evaluation [20/100]
INFO:tensorflow:Evaluation [30/100]
I1216 17:49:35.276600 140185970218816 evaluation.py:167] Evaluation [30/100]
INFO:tensorflow:Evaluation [40/100]
I1216 17:49:35.386603 140185970218816 evaluation.py:167] Evaluation [40/100]
INFO:tensorflow:Evaluation [50/100]
I1216 17:49:35.496302 140185970218816 evaluation.py:167] Evaluation [50/100]
INFO:tensorflow:Evaluation [60/100]
I1216 17:49:35.610811 140185970218816 evaluation.py:167] Evaluation [60/100]
INFO:tensorflow:Evaluation [70/100]
I1216 17:49:35.727595 140185970218816 evaluation.py:167] Evaluation [70/100]
INFO:tensorflow:Evaluation [80/100]
I1216 17:49:35.837867 140185970218816 evaluation.py:167] Evaluation [80/100]
INFO:tensorflow:Evaluation [90/100]
I1216 17:49:35.948000 140185970218816 evaluation.py:167] Evaluation [90/100]
INFO:tensorflow:Evaluation [100/100]
I1216 17:49:36.058386 140185970218816 evaluation.py:167] Evaluation [100/100]
2020-12-16 17:49:36.217190: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1987] Running auto_mixed_precision graph optimizer
2020-12-16 17:49:36.217736: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1343] No whitelist ops found, nothing to do
INFO:tensorflow:Finished evaluation at 2020-12-16-17:49:36
I1216 17:49:36.583616 140185970218816 evaluation.py:275] Finished evaluation at 2020-12-16-17:49:36
INFO:tensorflow:Saving dict for global step 50: global_step = 50, loss = 11.016237, masked_lm_accuracy = 0.0, masked_lm_loss = 10.320873, next_sentence_accuracy = 0.53, next_sentence_loss = 0.6954225
I1216 17:49:36.584346 140185970218816 estimator.py:2049] Saving dict for global step 50: global_step = 50, loss = 11.016237, masked_lm_accuracy = 0.0, masked_lm_loss = 10.320873, next_sentence_accuracy = 0.53, next_sentence_loss = 0.6954225
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1/model.ckpt-50
I1216 17:49:36.996846 140185970218816 estimator.py:2109] Saving 'checkpoint_path' summary for global step 50: /results/tf_bert_pretraining_lamb_base_fp16_gbs167584_gbs232768_201216153716/phase_1/model.ckpt-50
INFO:tensorflow:-----------------------------
I1216 17:49:36.998259 140185970218816 run_pretraining.py:682] -----------------------------
INFO:tensorflow:Total Inference Time = 14.67 for Sentences = 800
I1216 17:49:36.998534 140185970218816 run_pretraining.py:684] Total Inference Time = 14.67 for Sentences = 800
INFO:tensorflow:Total Inference Time W/O Overhead = 1.11 for Sentences = 792
I1216 17:49:36.998652 140185970218816 run_pretraining.py:686] Total Inference Time W/O Overhead = 1.11 for Sentences = 792
INFO:tensorflow:Summary Inference Statistics on EVAL set
I1216 17:49:36.998755 140185970218816 run_pretraining.py:687] Summary Inference Statistics on EVAL set
INFO:tensorflow:Batch size = 8
I1216 17:49:36.998852 140185970218816 run_pretraining.py:688] Batch size = 8
INFO:tensorflow:Sequence Length = 128
I1216 17:49:36.998993 140185970218816 run_pretraining.py:689] Sequence Length = 128
INFO:tensorflow:Precision = fp16
I1216 17:49:36.999096 140185970218816 run_pretraining.py:690] Precision = fp16
INFO:tensorflow:Throughput Average (sentences/sec) = 713.29
I1216 17:49:36.999191 140185970218816 run_pretraining.py:691] Throughput Average (sentences/sec) = 713.29
INFO:tensorflow:-----------------------------
I1216 17:49:36.999501 140185970218816 run_pretraining.py:693] -----------------------------
INFO:tensorflow:***** Eval results *****
I1216 17:49:36.999682 140185970218816 run_pretraining.py:697] ***** Eval results *****
INFO:tensorflow:  global_step = 50
I1216 17:49:36.999793 140185970218816 run_pretraining.py:699]   global_step = 50
INFO:tensorflow:  loss = 11.016237
I1216 17:49:37.000051 140185970218816 run_pretraining.py:699]   loss = 11.016237
INFO:tensorflow:  masked_lm_accuracy = 0.0
I1216 17:49:37.000175 140185970218816 run_pretraining.py:699]   masked_lm_accuracy = 0.0
INFO:tensorflow:  masked_lm_loss = 10.320873
I1216 17:49:37.000291 140185970218816 run_pretraining.py:699]   masked_lm_loss = 10.320873
INFO:tensorflow:  next_sentence_accuracy = 0.53
I1216 17:49:37.000402 140185970218816 run_pretraining.py:699]   next_sentence_accuracy = 0.53
INFO:tensorflow:  next_sentence_loss = 0.6954225
I1216 17:49:37.000499 140185970218816 run_pretraining.py:699]   next_sentence_loss = 0.6954225

DLL 2020-12-16 17:03:04.747140 - Iteration: 31  throughput_train : 488.369 seq/s mlm_loss : 10.4252  nsp_loss : 0.6708  total_loss : 11.0960  avg_loss_step : 11.1036  learning_rate : 1.0875e-05  loss_scaler : 134217728
DLL 2020-12-16 17:05:23.561040 - Iteration: 32  throughput_train : 487.407 seq/s mlm_loss : 10.4189  nsp_loss : 0.6796  total_loss : 11.0986  avg_loss_step : 11.1009  learning_rate : 1.125e-05  loss_scaler : 134217728
DLL 2020-12-16 17:07:42.320983 - Iteration: 33  throughput_train : 487.602 seq/s mlm_loss : 10.4483  nsp_loss : 0.6908  total_loss : 11.1391  avg_loss_step : 11.0978  learning_rate : 1.1625e-05  loss_scaler : 134217728
DLL 2020-12-16 17:10:01.276512 - Iteration: 34  throughput_train : 486.912 seq/s mlm_loss : 10.3850  nsp_loss : 0.6817  total_loss : 11.0667  avg_loss_step : 11.0960  learning_rate : 1.2e-05  loss_scaler : 134217728
DLL 2020-12-16 17:12:19.841491 - Iteration: 35  throughput_train : 488.274 seq/s mlm_loss : 10.4189  nsp_loss : 0.6646  total_loss : 11.0835  avg_loss_step : 11.0918  learning_rate : 1.2375001e-05  loss_scaler : 134217728
DLL 2020-12-16 17:14:38.428745 - Iteration: 36  throughput_train : 488.197 seq/s mlm_loss : 10.3898  nsp_loss : 0.6629  total_loss : 11.0527  avg_loss_step : 11.0881  learning_rate : 1.2750001e-05  loss_scaler : 134217728
DLL 2020-12-16 17:16:57.116221 - Iteration: 37  throughput_train : 487.870 seq/s mlm_loss : 10.4188  nsp_loss : 0.6644  total_loss : 11.0831  avg_loss_step : 11.0845  learning_rate : 1.3125001e-05  loss_scaler : 134217728
DLL 2020-12-16 17:19:15.737130 - Iteration: 38  throughput_train : 488.077 seq/s mlm_loss : 10.3919  nsp_loss : 0.6618  total_loss : 11.0537  avg_loss_step : 11.0798  learning_rate : 1.3500001e-05  loss_scaler : 134217728
DLL 2020-12-16 17:21:34.395590 - Iteration: 39  throughput_train : 487.944 seq/s mlm_loss : 10.3878  nsp_loss : 0.6568  total_loss : 11.0447  avg_loss_step : 11.0756  learning_rate : 1.3875e-05  loss_scaler : 134217728
DLL 2020-12-16 17:23:53.327233 - Iteration: 40  throughput_train : 487.001 seq/s mlm_loss : 10.3716  nsp_loss : 0.6534  total_loss : 11.0250  avg_loss_step : 11.0718  learning_rate : 1.425e-05  loss_scaler : 134217728
DLL 2020-12-16 17:26:12.174068 - Iteration: 41  throughput_train : 487.292 seq/s mlm_loss : 10.3708  nsp_loss : 0.7152  total_loss : 11.0860  avg_loss_step : 11.0689  learning_rate : 1.4625e-05  loss_scaler : 134217728
DLL 2020-12-16 17:28:30.956216 - Iteration: 42  throughput_train : 487.516 seq/s mlm_loss : 10.3630  nsp_loss : 0.6835  total_loss : 11.0465  avg_loss_step : 11.0645  learning_rate : 1.50000005e-05  loss_scaler : 134217728
DLL 2020-12-16 17:30:49.511222 - Iteration: 43  throughput_train : 488.310 seq/s mlm_loss : 10.3835  nsp_loss : 0.6721  total_loss : 11.0556  avg_loss_step : 11.0596  learning_rate : 1.5375e-05  loss_scaler : 134217728
DLL 2020-12-16 17:33:07.759164 - Iteration: 44  throughput_train : 489.370 seq/s mlm_loss : 10.3855  nsp_loss : 0.7077  total_loss : 11.0932  avg_loss_step : 11.0550  learning_rate : 1.575e-05  loss_scaler : 134217728
DLL 2020-12-16 17:35:26.010377 - Iteration: 45  throughput_train : 489.333 seq/s mlm_loss : 10.3801  nsp_loss : 0.6841  total_loss : 11.0642  avg_loss_step : 11.0519  learning_rate : 1.6125001e-05  loss_scaler : 134217728
DLL 2020-12-16 17:37:44.234140 - Iteration: 46  throughput_train : 489.437 seq/s mlm_loss : 10.3563  nsp_loss : 0.6752  total_loss : 11.0315  avg_loss_step : 11.0478  learning_rate : 1.65e-05  loss_scaler : 134217728
DLL 2020-12-16 17:40:02.808538 - Iteration: 47  throughput_train : 488.199 seq/s mlm_loss : 10.3574  nsp_loss : 0.6969  total_loss : 11.0544  avg_loss_step : 11.0437  learning_rate : 1.6875001e-05  loss_scaler : 134217728
DLL 2020-12-16 17:42:21.240334 - Iteration: 48  throughput_train : 488.706 seq/s mlm_loss : 10.3477  nsp_loss : 0.6731  total_loss : 11.0208  avg_loss_step : 11.0379  learning_rate : 1.725e-05  loss_scaler : 134217728
DLL 2020-12-16 17:44:39.571628 - Iteration: 49  throughput_train : 489.073 seq/s mlm_loss : 10.3400  nsp_loss : 0.6813  total_loss : 11.0213  avg_loss_step : 11.0322  learning_rate : 1.7625001e-05  loss_scaler : 134217728
DLL 2020-12-16 17:46:57.687394 - Iteration: 50  throughput_train : 489.825 seq/s mlm_loss : 10.3555  nsp_loss : 0.6849  total_loss : 11.0404  avg_loss_step : 11.0281  learning_rate : 1.8e-05  loss_scaler : 134217728
DLL 2020-12-16 17:49:16.201114 - Iteration: 51  throughput_train : 490.137 seq/s mlm_loss : 10.3335  nsp_loss : 0.7120  total_loss : 11.0455  avg_loss_step : 11.0229  learning_rate : 1.8375e-05  loss_scaler : 134217728
DLL 2020-12-16 17:49:22.327820 -  throughput_train : 433.636 seq/s
DLL 2020-12-16 17:49:36.999327 -  throughput_val : 713.2938785440158
